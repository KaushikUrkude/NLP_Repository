{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization**\n",
        "\n",
        "Lemmatization is a linguistic process that involves reducing words to their base or root form, known as the lemma. The lemma represents the canonical or dictionary form of a word. Unlike stemming, which involves removing suffixes to obtain a common root, lemmatization considers the context and meaning of a word and transforms it to its base form in a way that is linguistically valid."
      ],
      "metadata": {
        "id": "Fr6ZgA2hbHDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xUF6uCrR6ag",
        "outputId": "9fb908a9-d85b-4de1-c043-1b5ff08dcfd7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WordNetLemmatizer**"
      ],
      "metadata": {
        "id": "M9I_oQBuTFLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "uV4cORK_Qkh4"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"jumping\", \"jumped\", \"jumps\", \"runner\", \"running\", \"runs\", \"swimming\", \"swam\", \"swims\", \"actor\", \"actress\", \"acting\", \"runs\", \"friendly\", \"friendliness\", \"quickly\", \"quicker\", \"quickest\", \"organization\", \"organizational\"]\n"
      ],
      "metadata": {
        "id": "Yi9MY7fYRwhi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "## here WordNetLemmatizer() takes two argument word and pos\n",
        "## were pos can be by default its n\n",
        "# Noun -n\n",
        "# verb -v\n",
        "# adjective -a\n",
        "# adverb -r"
      ],
      "metadata": {
        "id": "RlJyEC60SE43"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trying the list with all four pos"
      ],
      "metadata": {
        "id": "w3HSd85Ta9vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"----->\"+lemmatizer.lemmatize(word,pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3pOPZxeSKcP",
        "outputId": "b6aa3501-3d91-484f-e489-8eefa0f0161b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumping----->jump\n",
            "jumped----->jump\n",
            "jumps----->jump\n",
            "runner----->runner\n",
            "running----->run\n",
            "runs----->run\n",
            "swimming----->swim\n",
            "swam----->swim\n",
            "swims----->swim\n",
            "actor----->actor\n",
            "actress----->actress\n",
            "acting----->act\n",
            "runs----->run\n",
            "friendly----->friendly\n",
            "friendliness----->friendliness\n",
            "quickly----->quickly\n",
            "quicker----->quicker\n",
            "quickest----->quickest\n",
            "organization----->organization\n",
            "organizational----->organizational\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"----->\"+lemmatizer.lemmatize(word,pos='a'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCs-0eRfZ_1H",
        "outputId": "3bcfcef5-4c71-412f-f805-2b2598fc7975"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumping----->jumping\n",
            "jumped----->jumped\n",
            "jumps----->jumps\n",
            "runner----->runner\n",
            "running----->running\n",
            "runs----->runs\n",
            "swimming----->swimming\n",
            "swam----->swam\n",
            "swims----->swims\n",
            "actor----->actor\n",
            "actress----->actress\n",
            "acting----->acting\n",
            "runs----->runs\n",
            "friendly----->friendly\n",
            "friendliness----->friendliness\n",
            "quickly----->quickly\n",
            "quicker----->quick\n",
            "quickest----->quick\n",
            "organization----->organization\n",
            "organizational----->organizational\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"----->\"+lemmatizer.lemmatize(word,pos='n'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ciWLWLgamJ_",
        "outputId": "aa1a1de4-0c36-48f6-f00c-c2f7a2fa221f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumping----->jumping\n",
            "jumped----->jumped\n",
            "jumps----->jump\n",
            "runner----->runner\n",
            "running----->running\n",
            "runs----->run\n",
            "swimming----->swimming\n",
            "swam----->swam\n",
            "swims----->swim\n",
            "actor----->actor\n",
            "actress----->actress\n",
            "acting----->acting\n",
            "runs----->run\n",
            "friendly----->friendly\n",
            "friendliness----->friendliness\n",
            "quickly----->quickly\n",
            "quicker----->quicker\n",
            "quickest----->quickest\n",
            "organization----->organization\n",
            "organizational----->organizational\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "  print(word+\"----->\"+lemmatizer.lemmatize(word,pos='r'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vPFBsjxauZA",
        "outputId": "6f929ab7-6971-4638-cf2a-29017a9d7b84"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jumping----->jumping\n",
            "jumped----->jumped\n",
            "jumps----->jumps\n",
            "runner----->runner\n",
            "running----->running\n",
            "runs----->runs\n",
            "swimming----->swimming\n",
            "swam----->swam\n",
            "swims----->swims\n",
            "actor----->actor\n",
            "actress----->actress\n",
            "acting----->acting\n",
            "runs----->runs\n",
            "friendly----->friendly\n",
            "friendliness----->friendliness\n",
            "quickly----->quickly\n",
            "quicker----->quicker\n",
            "quickest----->quickest\n",
            "organization----->organization\n",
            "organizational----->organizational\n"
          ]
        }
      ]
    }
  ]
}